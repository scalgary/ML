---
title: "Prelim"
format:
  html:
    code-fold: true
jupyter: python3
---

1 - Create a repo in Github and clone it on local drive
2 - Set up Python environnement
3 - Create core folder to keep my functions
4 - Create data folder
5 - function summarise
6 - check for quick linear regression
 python3 -m ipykernel install --user --name venv


# Packages
```{python}
import numpy as np
import pandas as pd
from matplotlib.pyplot import subplots
import statsmodels.api as sm
from statsmodels.stats.anova import anova_lm
from functools import partial
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline

```

# Personal Packages
```{python}
from core.helpers import summarize
from core.helpers import transform_df_for_model
from core.helpers import sklearn_sm
from core.helpers import CustomDataTransformer
```

# Linear regression : 1 variable
## Simple way
```{python}

Boston = pd.read_csv("data/Boston.csv")
df = pd.DataFrame({'intercept': np.ones(Boston.shape[0]),
                  'lstat': Boston['lstat']})
y = Boston['medv']
model = sm.OLS(y, df)
results = model.fit()
summarize(results)
```
## Using my own function
```{python}

X = transform_df_for_model(df,['lstat'])
y = Boston['medv']
model = sm.OLS(y, X)
results = model.fit()
summarize(results)
```

```{python}
results.summary()
```

### Predictions
```{python}
new_df = pd.DataFrame({'lstat':[5, 10, 15]})
variables = ['lstat']
newX = transform_df_for_model(new_df, variables)
newX
```


```{python}
new_predictions = results.get_prediction(newX)
print(new_predictions.predicted_mean)
new_predictions.conf_int(alpha=0.05)
```

Prediction interval
```{python}
new_predictions.conf_int(obs=True, alpha=0.05)
```

# Linear regression : 2 variables
```{python}
Boston = pd.read_csv("data/Boston.csv")
X = transform_df_for_model(Boston,['lstat', 'age'])
model1 = sm.OLS(y, X)
results1 = model1.fit()
summarize(results1)
```


```{python}
terms = Boston.columns.drop("medv")
X = transform_df_for_model(Boston, terms)
model = sm.OLS(y, X)
results = model.fit()
summarize(results)
```

## with interactions
```{python}
X = transform_df_for_model(Boston, ['lstat','age'],interactions = [('lstat', 'age')])
model2 = sm.OLS(y, X)

results2 = model2.fit()
summarize(model2.fit())
results2.summary()
```

How to use anova_lm
anova(reduced,full)
Ho no need the full model

```{python}

anova_lm(results1,results2)
```


```{python}
Carseats = pd.read_csv("data/Carseats.csv")

allvars = list(Carseats.columns.drop('Sales'))
y = Carseats['Sales']

X = transform_df_for_model(Carseats, allvars,[('Income', 'Advertising'),
                   ('Price', 'Age')])
model = sm.OLS(y, X)
summarize(model.fit())
```


# Split

```{python}
Auto = pd.read_csv('data/Auto.csv')
Auto_train, Auto_test = train_test_split(Auto,
                                         test_size=196,
                                         random_state=0)
```

## use of partial
```{python}

hp_mm = partial(transform_df_for_model, terms = ['horsepower'])
X_train = hp_mm(Auto_train)
y_train = Auto_train['mpg']
model = sm.OLS(y_train, X_train)
results = model.fit()
```
```{python}
X_test = hp_mm(Auto_test)
y_test = Auto_test['mpg']
test_pred = results.predict(X_test)
np.mean((y_test - test_pred)**2).item()
```

## Function to compute MSE
```{python}
def evalMSE(terms,
            response,
            train,
            test):

   mm_transform = partial(transform_df_for_model, terms = terms)
   X_train = mm_transform(train)
   y_train = train[response]

   X_test = mm_transform(test)
   y_test = test[response]

   results = sm.OLS(y_train, X_train).fit()
   test_pred = results.predict(X_test)

   return np.mean((y_test - test_pred)**2).item()
```


```{python}
evalMSE(terms =['horsepower','cylinders'],response ='mpg',train = Auto_train, test=Auto_test)
```


```{python}
from sklearn.model_selection import \
     (cross_validate,
      KFold,
      ShuffleSplit)
```


```{python}


# ðŸ“Œ DonnÃ©es factices
data = pd.read_csv("data/Boston.csv")

# ðŸ“Œ Variables et interactions
terms = ['lstat', 'age']

y = data['medv']


# ðŸ“Œ Construction du pipeline
pipeline = make_pipeline(
    CustomDataTransformer(terms),
    sm.OLS
)

# ðŸ“Œ EntraÃ®nement du modÃ¨le
pipeline.fit(data, y)

# ðŸ“Œ PrÃ©diction
predictions = pipeline.predict(data)

# ðŸ“Œ Affichage du rÃ©sumÃ© de la rÃ©gression
print(pipeline.named_steps["statsmodelslinearregression"].summary())
```


```{python}

# ðŸ“Œ DonnÃ©es factices
data = pd.read_csv("data/Boston.csv")

# ðŸ“Œ Variables et interactions
terms = ['lstat', 'age']

y = data['medv']


# ðŸ“Œ Construction du pipeline
pipeline = make_pipeline(
    CustomDataTransformer(terms),
    sm.OLS
)

# ðŸ“Œ EntraÃ®nement du modÃ¨le
pipeline.fit(data, y)
```