---
title: "Prelim"
format:
  html:
    code-fold: true
jupyter: python3
---

Il s'agit simplement de reprendre certains elements du lab de ISLP.
Pour des raisons de simplicite, je n'utilise pas le package ISLP qui contient des functions pour wrapper certaines functionnalites

```{python}
#| echo: false
# Import Packages
import numpy as np
import pandas as pd
from matplotlib.pyplot import subplots
import statsmodels.api as sm
from statsmodels.stats.anova import anova_lm
from functools import partial
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline

```


```{python}
#| echo: false
# Personal Packages
from core.helpers import summarize
from core.helpers import transform_df_for_model
from core.helpers import sklearn_sm
from core.helpers import CustomDataTransformer
```

Meme si c'est l'analyse la plus connue et simple, il est toujours important de bie comprendre la regression lineaire dont le plus gros avantage est 
# Linear regression : 1 variable
## Simple way
```{python}

Boston = pd.read_csv("data/Boston.csv")
df = pd.DataFrame({'intercept': np.ones(Boston.shape[0]),
                  'lstat': Boston['lstat']})
y = Boston['medv']
model = sm.OLS(y, df)
results = model.fit()
summarize(results)
```

J'ai repris l'idee du pacage ISLP qui est d'avoir une function dont l'objectif est de fitter les raw data pour creer une model.design matrice.
Tout simplement si on il s'agit d'avoir une pipeline pour que toutes les operations faites sur les donnees raw - soit facilement reproducibles

## Using my own function
```{python}

X = transform_df_for_model(df,['lstat']) #X just extract lstat variable from df and add an intercept variable
y = Boston['medv']
model = sm.OLS(y, X)
results = model.fit()
summarize(results)
```

```{python}
results.summary()
```

### Predictions
```{python}
new_df = pd.DataFrame({'lstat':[5, 10, 15]})
variables = ['lstat']
newX = transform_df_for_model(new_df, variables)
newX
```


```{python}
new_predictions = results.get_prediction(newX)
print(new_predictions.predicted_mean)
new_predictions.conf_int(alpha=0.05)
```

Prediction interval
```{python}
new_predictions.conf_int(obs=True, alpha=0.05)
```

# Linear regression : 2 variables
```{python}
Boston = pd.read_csv("data/Boston.csv")
X = transform_df_for_model(Boston,['lstat', 'age'])
model1 = sm.OLS(y, X)
results1 = model1.fit()
summarize(results1)
```


```{python}
terms = Boston.columns.drop("medv")
X = transform_df_for_model(Boston, terms)
model = sm.OLS(y, X)
results = model.fit()
summarize(results)
```

## with interactions
```{python}
X = transform_df_for_model(Boston, ['lstat','age'],interactions = [('lstat', 'age')])
model2 = sm.OLS(y, X)

results2 = model2.fit()
summarize(model2.fit())
results2.summary()
```


```{python}
Carseats = pd.read_csv("data/Carseats.csv")

allvars = list(Carseats.columns.drop('Sales'))
y = Carseats['Sales']

X = transform_df_for_model(Carseats, allvars,[('Income', 'Advertising'),
                   ('Price', 'Age')])
model = sm.OLS(y, X)
summarize(model.fit())
```

# How to compare two nested linear models
1 - full model
2 - reduced model
3 - Use of F-statistic to decide or not to rehject the reduced model in favor of the larger maodel

Ho = The two models are equally useful for predicting the outcome
Ha = The larger model is significantly better than the smaller model
p-value is the smallest significance level (alpha) at which you would reject the null hypothesis,



```{python}

anova_lm(results1,results2)
```
p_value is below my threshold of significance ( p< 0.05) so I cam reject the null hypotheses



# Validation

## Split

```{python}
Auto = pd.read_csv('data/Auto.csv')
Auto_train, Auto_test = train_test_split(Auto,
                                         test_size=196,
                                         random_state=0)
```

### Use of partial from functools
```{python}

hp_mm = partial(transform_df_for_model, terms = ['horsepower'])
X_train = hp_mm(Auto_train)
y_train = Auto_train['mpg']
model = sm.OLS(y_train, X_train)
results = model.fit()
```
```{python}
X_test = hp_mm(Auto_test)
y_test = Auto_test['mpg']
test_pred = results.predict(X_test)
np.mean((y_test - test_pred)**2).item()
```

### Function to compute MSE
MSE crucial metric for evaluating the performance of predictive models

```{python}
def evalMSE(terms,
            response,
            train,
            test):

   mm_transform = partial(transform_df_for_model, terms = terms)
   #X_train = transform_df_for_model(train, terms = terms)
   X_train = mm_transform(train)
   y_train = train[response]

   #X_test = transform_df_for_model(test, terms = terms)
   X_test = mm_transform(test)
   y_test = test[response]

   results = sm.OLS(y_train, X_train).fit()
   test_pred = results.predict(X_test)

   return np.mean((y_test - test_pred)**2).item()
```


```{python}
evalMSE(terms =['horsepower','cylinders'], response ='mpg', train = Auto_train, test = Auto_test)
```

```{python}
evalMSE(terms =['horsepower'], response ='mpg', train = Auto_train, test = Auto_test)
```


## Leave-One-Out (LOO)
```{python}
Auto = pd.read_csv("data/Auto.csv")
from sklearn.model_selection import \
     (cross_validate,
      KFold,
      ShuffleSplit)
hp_model = make_pipeline(
    CustomDataTransformer(['horsepower']), # instead of using the function transfor_df_for_model we use a class and the fit methode use the formction transform_df_for_model
    sklearn_sm(sm.OLS)) # wrapper sm.OLS for matching sklearn structure
#hp_model = linear regression on variable horsepoer (+intercept)
X, Y = Auto.drop(columns=['mpg']), Auto['mpg']
cv_results = cross_validate(hp_model,
                            X,
                            Y,
                            cv=Auto.shape[0]) #Leave-One-Out (LOO)
cv_err = np.mean(cv_results['test_score'])
cv_err
```


```{python}

from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score, KFold
import pandas as pd

# ðŸ“Œ Charger les donnÃ©es
Auto = pd.read_csv("data/Auto.csv")
X, Y = Auto.drop(columns=['mpg']), Auto['mpg']

# ðŸ“Œ Variables pour la transformation
terms = ['horsepower']

# ðŸ“Œ DÃ©finir le pipeline
pipeline = make_pipeline(
    CustomDataTransformer(terms),
sklearn_sm(sm.OLS))

# ðŸ“Œ Validation croisÃ©e
cv = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(pipeline, X, Y, cv=cv, scoring="neg_mean_squared_error")  # MSE nÃ©gatif

# ðŸ“Œ Affichage des rÃ©sultats
print("Scores de validation croisÃ©e (MSE nÃ©gatif) :", scores)
print("MSE moyen :", -np.mean(scores))  # Convertir en MSE positif
```


```{python}
cv_error = np.zeros(5)
H = np.array(Auto['horsepower'])
M = sklearn_sm(sm.OLS)
for i, d in enumerate(range(1,6)):
    X = np.power.outer(H, np.arange(d+1))
    M_CV = cross_validate(M,
                          X,
                          Y,
                          cv=Auto.shape[0])
    cv_error[i] = np.mean(M_CV['test_score'])
cv_error
```


```{python}
cv_error = np.zeros(5)
cv = KFold(n_splits=10,
           shuffle=True,
           random_state=0) # use same splits for each degree
M = sklearn_sm(sm.OLS)
for i, d in enumerate(range(1,6)):
    X = np.power.outer(H, np.arange(d+1))
    M_CV = cross_validate(M,
                          X,
                          Y,
                          cv=cv)
    cv_error[i] = np.mean(M_CV['test_score'])
cv_error
```


```{python}
# ðŸ“Œ DÃ©finir le pipeline
hp_model = make_pipeline(
    CustomDataTransformer(terms),
sklearn_sm(sm.OLS))
```

```{python}
Auto.shape
```
```{python}
validation = ShuffleSplit(n_splits=1,
                          test_size=196,
                          random_state=0)
results = cross_validate(hp_model,
                         Auto.drop(['mpg'], axis=1),
                         Auto['mpg'],
                         cv=validation)
results['test_score']
```


```{python}
Portfolio = pd.read_csv('data/Portfolio.csv')
def alpha_func(D, idx):
   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)
   return ((cov_[1,1] - cov_[0,1]) /
           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))
```


```{python}
alpha_func(Portfolio, range(100))
```


```{python}
rng = np.random.default_rng(0)
alpha_func(Portfolio,
           rng.choice(100,
                      100,
                      replace=True))
```


he bootstrap standard error for arbitrary
functions 

```{python}
def boot_SE(func,
            D,
            n=None,
            B=1000,
            seed=0):
    rng = np.random.default_rng(seed)
    first_, second_ = 0, 0
    n = n or D.shape[0]
    for _ in range(B):
        idx = rng.choice(D.index, #sampling idx
                         n,
                         replace=True)
        value = func(D, idx) # function on the idx
        first_ += value
        second_ += value**2
    return np.sqrt(second_ / B - (first_ / B)**2)
```


```{python}
alpha_SE = boot_SE(alpha_func,
                   Portfolio,
                   B=1000,
                   seed=0)
alpha_SE
```


```{python}
def boot_OLS(model_matrix, response, D, idx):
    D_ = D.loc[idx]
    Y_ = D_[response]
    X_ = clone(model_matrix).fit_transform(D_)
    return sm.OLS(Y_, X_).fit().params
```


```{python}
pipeline = pipeline

hp_model = make_pipeline(
    CustomDataTransformer(['horsepower']))
hp_func = partial(boot_OLS, hp_model, 'mpg')
```

```{python}
Auto =Auto.set_index('name')
```
```{python}
from sklearn.base import clone
rng = np.random.default_rng(0)
np.array([hp_func(Auto,
          rng.choice(Auto.index,
                     392,
                     replace=True)) for _ in range(10)])
```


```{python}
hp_se = boot_SE(hp_func,
                Auto,
                B=1000,
                seed=10)
hp_se
```

